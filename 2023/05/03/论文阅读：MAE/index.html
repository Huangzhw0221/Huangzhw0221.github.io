<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="Huang Zhiwei">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://evan.beee.top" crossorigin>
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="https://huangzhw0221.github.io/2023/05/03/论文阅读：mae/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta name="description" content="MAELink: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2111.06377 备注: MAE原始论文，本记录参考自视频 43、逐行讲解Masked AutoEncoder(MAE)的PyTorch代码_哔哩哔哩_bilibili   掩码自编码器(MAE)是一种简单的自编码方法，可以在给定部分观测值的情况下重建原始图像。 方法掩码效仿VIT，将图像划分为规则的不重叠的小块。然后对patch进">
<meta property="og:type" content="article">
<meta property="og:title" content="论文阅读：MAE">
<meta property="og:url" content="https://huangzhw0221.github.io/2023/05/03/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AMAE/index.html">
<meta property="og:site_name" content="Huang&#39;s Matrix">
<meta property="og:description" content="MAELink: https:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2111.06377 备注: MAE原始论文，本记录参考自视频 43、逐行讲解Masked AutoEncoder(MAE)的PyTorch代码_哔哩哔哩_bilibili   掩码自编码器(MAE)是一种简单的自编码方法，可以在给定部分观测值的情况下重建原始图像。 方法掩码效仿VIT，将图像划分为规则的不重叠的小块。然后对patch进">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://huangzhw0221.github.io/blogImages/Untitled.png">
<meta property="article:published_time" content="2023-05-03T14:57:32.000Z">
<meta property="article:modified_time" content="2023-05-03T14:59:16.224Z">
<meta property="article:author" content="Huang Zhiwei">
<meta property="article:tag" content="论文阅读">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://huangzhw0221.github.io/blogImages/Untitled.png">
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/redefine-favicon.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/redefine-favicon.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/redefine-favicon.svg">
    <!--- Page Info-->
    
    <title>
        
            论文阅读：MAE -
        
        Huang&#39;s Matrix
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/assets/fonts.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"huangzhw0221.github.io","root":"/","language":"zh-CN"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"14px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[""]},"code_block":{"copy":true,"style":"mac","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":true,"lazyload":true,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true},"home_banner":{"enable":true,"image":{"light":"https://images.pexels.com/photos/691668/pexels-photo-691668.jpeg","dark":"https://images.pexels.com/photos/461956/pexels-photo-461956.jpeg"},"title":"白云怡意 清泉洗心","subtitle":{"text":[],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":true,"smart_backspace":true},"text_color":{"light":"#fff","dark":"#d1d1b6"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"links":{"github":null,"instagram":null,"zhihu":null,"twitter":null,"email":null}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.1.2","navbar":{"auto_hide":false,"color":{"left":"#f78736","right":"#367df7","transparency":35},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Tags":{"path":"/tags","icon":"fa-regular fa-tags"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}}};
    Global.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
            <a class="logo-title" href="/">
                
                Huang&#39;s Matrix
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        首页
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                首页
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">论文阅读：MAE</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/redefine-avatar.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">Huang Zhiwei</span>
                            
                                <span class="author-label"></span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-05-03 22:57:32</span>
        <span class="mobile">2023-05-03 22:57</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-05-03 22:59:16</span>
            <span class="mobile">2023-05-03 22:59</span>
            <span class="hover-info">更新</span>
        </span>
    

    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">论文阅读</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h1 id="MAE"><a href="#MAE" class="headerlink" title="MAE"></a>MAE</h1><p>Link: <a class="link"   target="_blank" rel="noopener" href="https://arxiv.org/abs/2111.06377" >https://arxiv.org/abs/2111.06377 <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a><br>备注: MAE原始论文，本记录参考自视频</p>
<p><a class="link"   target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1JS4y1N7XE/?spm_id_from=333.880.my_history.page.click" >43、逐行讲解Masked AutoEncoder(MAE)的PyTorch代码_哔哩哔哩_bilibili <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<p><img  
                     lazyload
                     src="/images/loading.svg"
                     data-src="/../../../blogImages/Untitled.png"
                      alt="Untitled"
                ></p>
<p>掩码自编码器(MAE)是一种简单的自编码方法，可以在给定部分观测值的情况下重建原始图像。</p>
<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><h2 id="掩码"><a href="#掩码" class="headerlink" title="掩码"></a>掩码</h2><p>效仿VIT，将图像划分为规则的不重叠的小块。然后对patch进行采样，并掩码(即删除)剩余的patch。我们的采样策略很简单:我们对随机斑块进行采样，不进行替换，遵循均匀分布。</p>
<p>文中解释了选取较高的掩码率的原因：去除冗余信息，如果掩码率较小，那么编码器很容易就从大量冗余信息中还原出原图像，但模型需要编码器学习更好的特征，所以掩码率会比较高。</p>
<h2 id="MAE-encoder"><a href="#MAE-encoder" class="headerlink" title="MAE encoder"></a>MAE encoder</h2><p>编码器就是VIT的编码器，它的输入是采样得到的25%原来的patch，将他们打上位置编码就可以送入transformer块，输出也将是同样的尺寸。</p>
<h2 id="MAE-decoder"><a href="#MAE-decoder" class="headerlink" title="MAE decoder"></a>MAE decoder</h2><p>解码器的输出是完整的patch序列，解码器的输入是可见的编码器输出和不可见的token。这些不可见的token也是可学习的。这些token会被加上原来位置的位置编码，如果不加就缺失了位置信息。</p>
<p>解码器仅仅在预训练阶段有用，在下游任务上有用的仅仅是编码器。编解码器可以独立设计。</p>
<h2 id="重构目标"><a href="#重构目标" class="headerlink" title="重构目标"></a>重构目标</h2><p>MAE通过预测每个被屏蔽token的像素值来重建输入，解码器输出中的每个元素都是代表一个patch的像素值向量。所以重构损失就是对应像素的mean squared error (MSE)，这个损失只对被掩码的token做，未被掩码的token不需要计算该损失。</p>
<p>作者讨论了是否对每个patch做均值方差归一化后再做损失，其结论是做了归一化后效果会更好。</p>
<h2 id="关于实现"><a href="#关于实现" class="headerlink" title="关于实现"></a>关于实现</h2><ul>
<li>首先为每个小patch生成一个embedding，然后加上对应的位置编码；</li>
<li>然后用shuffle操作打散，根据掩码率取前25%的patch；</li>
<li>送入Vit后，将输出的patch根据unshuffle操作还原到原始序列的对应位置上去；</li>
<li>对masked token用一个特殊的token代替，然后给完整的序列加上位置编码，送入解码器；</li>
</ul>
<h1 id="代码解读"><a href="#代码解读" class="headerlink" title="代码解读"></a>代码解读</h1><h2 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h2><p>先看models_mae.py</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, img_size=<span class="number">224</span>, patch_size=<span class="number">16</span>, in_chans=<span class="number">3</span>,</span></span><br><span class="line"><span class="params">                 embed_dim=<span class="number">1024</span>, depth=<span class="number">24</span>, num_heads=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">                 decoder_embed_dim=<span class="number">512</span>, decoder_depth=<span class="number">8</span>, decoder_num_heads=<span class="number">16</span>,</span></span><br><span class="line"><span class="params">                 mlp_ratio=<span class="number">4.</span>, norm_layer=nn.LayerNorm, norm_pix_loss=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># MAE encoder specifics</span></span><br><span class="line">        <span class="comment"># patchembedding</span></span><br><span class="line">        self.patch_embed = PatchEmbed(img_size, patch_size, in_chans, embed_dim)</span><br><span class="line">        num_patches = self.patch_embed.num_patches</span><br><span class="line">        <span class="comment"># class token</span></span><br><span class="line">        self.cls_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, embed_dim))</span><br><span class="line">        <span class="comment"># 位置编码，长度是patch个数加class token</span></span><br><span class="line">        self.pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, embed_dim), requires_grad=<span class="literal">False</span>)  <span class="comment"># fixed sin-cos embedding</span></span><br><span class="line">        <span class="comment"># 重复模块depth次</span></span><br><span class="line">        self.blocks = nn.ModuleList([</span><br><span class="line">            Block(embed_dim, num_heads, mlp_ratio, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(depth)])</span><br><span class="line">        self.norm = norm_layer(embed_dim)</span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line">        <span class="comment"># MAE decoder specifics</span></span><br><span class="line">        self.decoder_embed = nn.Linear(embed_dim, decoder_embed_dim, bias=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        self.mask_token = nn.Parameter(torch.zeros(<span class="number">1</span>, <span class="number">1</span>, decoder_embed_dim))</span><br><span class="line"></span><br><span class="line">        self.decoder_pos_embed = nn.Parameter(torch.zeros(<span class="number">1</span>, num_patches + <span class="number">1</span>, decoder_embed_dim), requires_grad=<span class="literal">False</span>)  <span class="comment"># fixed sin-cos embedding</span></span><br><span class="line"></span><br><span class="line">        self.decoder_blocks = nn.ModuleList([</span><br><span class="line">            Block(decoder_embed_dim, decoder_num_heads, mlp_ratio, qkv_bias=<span class="literal">True</span>, qk_scale=<span class="literal">None</span>, norm_layer=norm_layer)</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(decoder_depth)])</span><br><span class="line">        <span class="comment"># 解码器输出归一化</span></span><br><span class="line">        self.decoder_norm = norm_layer(decoder_embed_dim)</span><br><span class="line">        <span class="comment"># 线性层，输出是patch面积*3通道</span></span><br><span class="line">        self.decoder_pred = nn.Linear(decoder_embed_dim, patch_size**<span class="number">2</span> * in_chans, bias=<span class="literal">True</span>) <span class="comment"># decoder to patch</span></span><br><span class="line">        <span class="comment"># --------------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">        self.norm_pix_loss = norm_pix_loss</span><br><span class="line"></span><br><span class="line">        self.initialize_weights()</span><br></pre></td></tr></table></figure></div>

<p>初始化权重的函数<code>initialize_weights</code>和<code>_init_weights</code>主要是对位置编码做了固定参数的初始化（无梯度）、patch embedding做了均值初始化、对每一层的线形层、归一化层做了平均初始化。</p>
<p><code>patchify</code>函数和<code>unpatchify</code>函数做了将图像分patch和拼接成图像的操作，<code>random_masking</code>函数就是随机掩码，其中用到了如下函数：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 生成和patch尺寸一样的随机张量</span></span><br><span class="line">noise = torch.rand(N, L, device=x.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># sort noise for each sample</span></span><br><span class="line"><span class="comment"># 根据第一个维度排序（sequence length维度），那么这个顺序就是打乱的顺序，相应的将这个排序的索引再排序就是还原的顺序了。</span></span><br><span class="line">ids_shuffle = torch.argsort(noise, dim=<span class="number">1</span>)  <span class="comment"># ascend: small is keep, large is remove</span></span><br><span class="line">ids_restore = torch.argsort(ids_shuffle, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></div>

<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#随机生成的张量</span></span><br><span class="line">tensor([<span class="number">0.6141</span>, <span class="number">0.9232</span>, <span class="number">0.5108</span>, <span class="number">0.0047</span>, <span class="number">0.6740</span>])</span><br><span class="line"><span class="comment">#张量排序</span></span><br><span class="line">tensor([<span class="number">3</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment">#第二个位置的元素是原序列的第0个，第4个位置的元素是原序列的第1个。。。</span></span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure></div>

<p>随后根据torch.gather和ids_keep即序列维度上需要被取的那些索引得到未被掩码的序列x_masked ；同理得到mask 表示被掩码的token；</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_masked = torch.gather(x, dim=<span class="number">1</span>, index=ids_keep.unsqueeze(-<span class="number">1</span>).repeat(<span class="number">1</span>, <span class="number">1</span>, D))</span><br><span class="line">mask = torch.gather(mask, dim=<span class="number">1</span>, index=ids_restore)</span><br></pre></td></tr></table></figure></div>

<p>剩余的<code>forward_encoder</code> 和 <code>forward_decoder</code> 没特别大的难度，略过。</p>
<p><code>forward_loss</code> 损失中就是普通的mse loss，但是如果要做归一化的话，会进入分支先计算patch的均值和方差。此外由于只预测被掩码的部分，所以需要乘上掩码再计算损失。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">loss = (loss * mask).<span class="built_in">sum</span>() / mask.<span class="built_in">sum</span>()</span><br></pre></td></tr></table></figure></div>

<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>训练的代码支持cpu、单卡、多卡，已经非常完美了，我们要训练自己的数据集只需要修改data_path变量即可。训练代码的前153行都是在初始化和准备数据加载器。</p>
<p>代码使用了ddp包裹模型，在160行：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model_without_ddp = model</span><br></pre></td></tr></table></figure></div>

<p>并在174行做了检验：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> args.distributed:</span><br><span class="line">        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu], find_unused_parameters=<span class="literal">True</span>)</span><br><span class="line">        model_without_ddp = model.module</span><br></pre></td></tr></table></figure></div>

<p>训练代码的主体如下：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(args.start_epoch, args.epochs):</span><br><span class="line">		<span class="comment">#分布式训练要确保每张卡分到的数据不一样</span></span><br><span class="line">    <span class="keyword">if</span> args.distributed:</span><br><span class="line">        data_loader_train.sampler.set_epoch(epoch)</span><br><span class="line">		<span class="comment">#外层循环只有epoch，还有一层循环即一次epoch遍历数据的循环写在了train_one_epoch中</span></span><br><span class="line">    train_stats = train_one_epoch(</span><br><span class="line">        model, data_loader_train,</span><br><span class="line">        optimizer, device, epoch, loss_scaler,</span><br><span class="line">        log_writer=log_writer,</span><br><span class="line">        args=args</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> args.output_dir <span class="keyword">and</span> (epoch % <span class="number">20</span> == <span class="number">0</span> <span class="keyword">or</span> epoch + <span class="number">1</span> == args.epochs):</span><br><span class="line">				<span class="comment"># misc库的保存模型函数</span></span><br><span class="line">        misc.save_model(</span><br><span class="line">            args=args, model=model, model_without_ddp=model_without_ddp, optimizer=optimizer,</span><br><span class="line">            loss_scaler=loss_scaler, epoch=epoch)</span><br><span class="line"></span><br><span class="line">    log_stats = &#123;**&#123;<span class="string">f&#x27;train_<span class="subst">&#123;k&#125;</span>&#x27;</span>: v <span class="keyword">for</span> k, v <span class="keyword">in</span> train_stats.items()&#125;,</span><br><span class="line">                    <span class="string">&#x27;epoch&#x27;</span>: epoch,&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.output_dir <span class="keyword">and</span> misc.is_main_process():</span><br><span class="line">        <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            log_writer.flush()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(os.path.join(args.output_dir, <span class="string">&quot;log.txt&quot;</span>), mode=<span class="string">&quot;a&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(json.dumps(log_stats) + <span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure></div>

<p>train_one_epoch函数中的训练主体如下</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于是自监督学习，所以(samples, _)即样本和标签中的标签是不需要的</span></span><br><span class="line"><span class="keyword">for</span> data_iter_step, (samples, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(metric_logger.log_every(data_loader, print_freq, header)):</span><br><span class="line"></span><br><span class="line"><span class="comment"># we use a per iteration (instead of per epoch) lr scheduler</span></span><br><span class="line"><span class="keyword">if</span> data_iter_step % accum_iter == <span class="number">0</span>:</span><br><span class="line">        lr_sched.adjust_learning_rate(optimizer, data_iter_step / <span class="built_in">len</span>(data_loader) + epoch, args)</span><br><span class="line"></span><br><span class="line">    samples = samples.to(device, non_blocking=<span class="literal">True</span>)</span><br><span class="line">		<span class="comment"># 混合精度</span></span><br><span class="line">    <span class="keyword">with</span> torch.cuda.amp.autocast():</span><br><span class="line">        loss, _, _ = model(samples, mask_ratio=args.mask_ratio)</span><br><span class="line"></span><br><span class="line">    loss_value = loss.item()</span><br><span class="line">		</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> math.isfinite(loss_value):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Loss is &#123;&#125;, stopping training&quot;</span>.<span class="built_in">format</span>(loss_value))</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line">		<span class="comment"># 判断是否需要参数更新，并做参数更新</span></span><br><span class="line">    loss /= accum_iter</span><br><span class="line">    loss_scaler(loss, optimizer, parameters=model.parameters(),</span><br><span class="line">                update_grad=(data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">if</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">    torch.cuda.synchronize()</span><br><span class="line"></span><br><span class="line">    metric_logger.update(loss=loss_value)</span><br><span class="line"></span><br><span class="line">    lr = optimizer.param_groups[<span class="number">0</span>][<span class="string">&quot;lr&quot;</span>]</span><br><span class="line">    metric_logger.update(lr=lr)</span><br><span class="line">	</span><br><span class="line">    loss_value_reduce = misc.all_reduce_mean(loss_value)</span><br><span class="line">		<span class="comment"># 日志相关</span></span><br><span class="line">    <span class="keyword">if</span> log_writer <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span> <span class="keyword">and</span> (data_iter_step + <span class="number">1</span>) % accum_iter == <span class="number">0</span>:</span><br><span class="line">        <span class="string">&quot;&quot;&quot; We use epoch_1000x as the x-axis in tensorboard.</span></span><br><span class="line"><span class="string">        This calibrates different curves when batch size changes.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        epoch_1000x = <span class="built_in">int</span>((data_iter_step / <span class="built_in">len</span>(data_loader) + epoch) * <span class="number">1000</span>)</span><br><span class="line">        log_writer.add_scalar(<span class="string">&#x27;train_loss&#x27;</span>, loss_value_reduce, epoch_1000x)</span><br><span class="line">        log_writer.add_scalar(<span class="string">&#x27;lr&#x27;</span>, lr, epoch_1000x)</span><br></pre></td></tr></table></figure></div>

<p>根据视频所说，如果使用最新的timm需要将models_mae.py中的qk_scale注释掉。</p>
<h2 id="微调"><a href="#微调" class="headerlink" title="微调"></a>微调</h2><p>微调中的大部分和训练是一样的，它的数据集加载器使用了<code>build_dataset</code> 函数，其中做了额外的图像强增强。</p>
<p>在218行使用了mixup增强，是一种在分类任务上有效的增强方式。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mixup_fn = <span class="literal">None</span></span><br><span class="line">mixup_active = args.mixup &gt; <span class="number">0</span> <span class="keyword">or</span> args.cutmix &gt; <span class="number">0.</span> <span class="keyword">or</span> args.cutmix_minmax <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line"><span class="keyword">if</span> mixup_active:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Mixup is activated!&quot;</span>)</span><br><span class="line">    mixup_fn = Mixup(</span><br><span class="line">        mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,</span><br><span class="line">        prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,</span><br><span class="line">        label_smoothing=args.smoothing, num_classes=args.nb_classes)</span><br></pre></td></tr></table></figure></div>

<p>在导入模型时使用的vit写法和models_vit不一样但是参数上是一样的，且在导入参数后确保新加的两层分类层参数未被导入。</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load pre-trained model</span></span><br><span class="line">msg = model.load_state_dict(checkpoint_model, strict=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(msg)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> args.global_pool:</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">set</span>(msg.missing_keys) == &#123;<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>, <span class="string">&#x27;fc_norm.weight&#x27;</span>, <span class="string">&#x27;fc_norm.bias&#x27;</span>&#125;</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">set</span>(msg.missing_keys) == &#123;<span class="string">&#x27;head.weight&#x27;</span>, <span class="string">&#x27;head.bias&#x27;</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></div>

<p>分类损失的选择上也做了一些判断：</p>
<div class="highlight-container" data-rel="Python"><figure class="iseeu highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> mixup_fn <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line"><span class="comment"># smoothing is handled with mixup label transform</span></span><br><span class="line">criterion = SoftTargetCrossEntropy()</span><br><span class="line"><span class="keyword">elif</span> args.smoothing &gt; <span class="number">0.</span>:</span><br><span class="line">    criterion = LabelSmoothingCrossEntropy(smoothing=args.smoothing)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    criterion = torch.nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure></div>

            </div>

            
                <div class="post-copyright-info">
                    <div class="article-copyright-info-container">
    <ul>
        <li><strong>标题:</strong> 论文阅读：MAE</li>
        <li><strong>作者:</strong> Huang Zhiwei</li>
        <li><strong>创建于:</strong> 2023-05-03 22:57:32</li>
        
            <li>
                <strong>更新于:</strong> 2023-05-03 22:59:16
            </li>
        
        <li>
            <strong>链接:</strong> https://huangzhw0221.github.io/2023/05/03/论文阅读：MAE/
        </li>
        <li>
            <strong>版权声明:</strong> 本文章采用 <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a> 进行许可。
        </li>
    </ul>
</div>

                </div>
            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/">#论文阅读</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2023/06/09/rabbitmq/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">rabbitmq</span>
                                    <span class="post-nav-item">上一篇</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/05/03/%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95%E5%9F%BA%E7%A1%80/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">测试方法基础</span>
                                    <span class="post-nav-item">下一篇</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
                <div class="comment-container">
                    <div class="comments-container">
    <div id="comment-anchor"></div>
    <div class="comment-area-title">
        <i class="fa-solid fa-comments"></i>&nbsp;评论
    </div>
    

        
            
 
    <div id="waline"></div>
    <script type="module"  data-pjax>
        import { init } from 'https://evan.beee.top/js/waline.mjs';

        function loadWaline() {
            init({
                el: '#waline',
                serverURL: 'https://example.example.com',
                lang: 'zh-CN',
                dark: 'body[class~="dark-mode"]',
                requiredMeta: ['nick','mail'], // cannot customize by theme config, change it yourself
            });
        }

        if ('true') {
            const loadWalineTimeout = setTimeout(() => {
                loadWaline();
                clearTimeout(loadWalineTimeout);
            }, 1000);
        } else {
            window.addEventListener('DOMContentLoaded', loadWaline);
        }
        
    </script>



        
    
</div>

                </div>
            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">此页目录</div>
        <div class="page-title">论文阅读：MAE</div>
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#MAE"><span class="nav-text">MAE</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-text">方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8E%A9%E7%A0%81"><span class="nav-text">掩码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MAE-encoder"><span class="nav-text">MAE encoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MAE-decoder"><span class="nav-text">MAE decoder</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%87%8D%E6%9E%84%E7%9B%AE%E6%A0%87"><span class="nav-text">重构目标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E5%AE%9E%E7%8E%B0"><span class="nav-text">关于实现</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB"><span class="nav-text">代码解读</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-text">模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83"><span class="nav-text">训练</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BE%AE%E8%B0%83"><span class="nav-text">微调</span></a></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2022</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-heart fa-beat" style="--fa-animation-duration: 0.5s; color: #f54545"></i>&nbsp;&nbsp;<a href="/">Huang Zhiwei</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        总访问量&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a> 驱动</span>
                <br>
            <span class="theme-version-container">主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.1.2</a>
        </div>
        
        
        
            <div id="start_div" style="display:none">
                2022/8/17 11:45:14
            </div>
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
            <li class="go-comment">
                <i class="fa-regular fa-comments"></i>
            </li>
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/navbarShrink.js"></script>

<script src="/js/tools/scrollTopBottom.js"></script>

<script src="/js/tools/lightDarkSwitch.js"></script>





    
<script src="/js/tools/codeBlock.js"></script>




    
<script src="/js/layouts/lazyload.js"></script>




    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/layouts/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts pjax">
    
        
<script src="/js/tools/tocToggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
